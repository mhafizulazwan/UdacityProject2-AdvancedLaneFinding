{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "i = 0 #counter for saving images\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    raw_img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        # Undistort the image \n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,imgpoints, gray.shape[::-1],None, None)\n",
    "        undistorted = cv2.undistort(raw_img, mtx, dist, None, mtx)\n",
    "        \n",
    "        # Display the chessboard corners and undistorted images \n",
    "        plt.figure()\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize = (24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Distorted Image', fontsize=50)\n",
    "        ax2.imshow(undistorted)\n",
    "        ax2.set_title('Undistorted Image', fontsize=50)\n",
    "        \n",
    "        # Save the figures\n",
    "        i = i + 1\n",
    "        figname = 'undistorted_{}.png'.format(i)\n",
    "        dest = os.path.join('../output_images/undistorted_chessboard_images/', figname)\n",
    "        plt.savefig(dest)\n",
    "        plt.close('all') #un/comment here to see the plot inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Absolute threshold function\n",
    "def abs_sobel_thresh(gray, orient = 'x', grad_thresh = (0,255)):\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "        abs_sobel = np.absolute(sobelx)\n",
    "        \n",
    "    elif orient == 'y':\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "        abs_sobel = np.absolute(sobely)\n",
    "        \n",
    "    scaled_sobel = np.uint(255*abs_sobel/np.max(abs_sobel)) # scaled to 8-bit (range 0-255)\n",
    "    \n",
    "    # Create a binary mask\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= grad_thresh[0]) & (scaled_sobel <= grad_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# Magnitude threshold function\n",
    "def mag_thresh(gray, sobel_kernel = 3, mag_thresh=(0,255)):\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    scaled_sobel = np.uint(255*mag_sobel/np.max(mag_sobel)) # scaled to 8-bit (range 0-255)\n",
    "    \n",
    "    # Create a binary mask\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Direction threshold function\n",
    "def dir_thresh(gray, sobel_kernel = 3, dir_thresh=(0,np.pi/2)):\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    absgraddir = np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "    \n",
    "    # Create a binary mask\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= dir_thresh[0]) & (absgraddir <= dir_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def color_thresh(hls, color_thresh = (0,255)):\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= color_thresh[0]) & (s_channel <= color_thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using combined thresholds (gradient, magnitude, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../test_images/straight_lines*.jpg')\n",
    "ksize = 15\n",
    "i = 0 #counter for saving images\n",
    "\n",
    "for fname in images:\n",
    "    \n",
    "    image = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    gradx_binary = abs_sobel_thresh(gray, orient='x', grad_thresh = (20,200))\n",
    "    grady_binary = abs_sobel_thresh(gray, orient='y', grad_thresh = (20,200))\n",
    "    mag_binary = mag_thresh(gray, sobel_kernel = ksize, mag_thresh=(30, 200))\n",
    "    dir_binary = dir_thresh(gray, sobel_kernel = ksize, dir_thresh=(0.7, 1.0))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx_binary == 1) & (grady_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "    # Plot the result\n",
    "    plt.figure()\n",
    "    f, axs = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Original Image', fontsize=50)\n",
    "    axs[1].imshow(combined, cmap='gray')\n",
    "    axs[1].set_title('Combined Thresholds', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save the figures\n",
    "    i = i + 1\n",
    "    figname = 'combined_thresh_{}.png'.format(i)\n",
    "    dest = os.path.join('../output_images/combined_threshold', figname)\n",
    "    plt.savefig(dest)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using combined color and gradient thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../test_images/test*.jpg')\n",
    "i = 2 #counter for saving images\n",
    "\n",
    "for fname in images:\n",
    "    \n",
    "    image = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    gradx_binary = abs_sobel_thresh(hls[:,:,1], orient='x', grad_thresh = (20,200))\n",
    "    color_binary = color_thresh(hls, color_thresh = (170,255))\n",
    "\n",
    "    combined = np.zeros_like(gradx_binary)\n",
    "    combined[(gradx_binary == 1) | (color_binary == 1)] = 1\n",
    "    \n",
    "    # Plot the result\n",
    "    plt.figure()\n",
    "    f, axs = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Original Image', fontsize=50)\n",
    "    axs[1].imshow(combined, cmap='gray')\n",
    "    axs[1].set_title('Combined Thresholds', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    # Save the figures\n",
    "    i = i + 1\n",
    "    figname = 'color_gradient_{}.png'.format(i)\n",
    "    dest = os.path.join('../output_images/color_gradient/', figname)\n",
    "    plt.savefig(dest)\n",
    "    plt.close('all') #un/comment here to see the plot inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectify binary image using a perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking (select a region of interest)\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1975d520765f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mvertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_right\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbottom_right\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbottom_left\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-49a37e2131c9>\u001b[0m in \u001b[0;36mregion_of_interest\u001b[0;34m(img, vertices)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#filling pixels inside the polygon defined by \"vertices\" with the fill color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillPoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_mask_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#returning the image only where mask pixels are nonzero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'img'"
     ]
    }
   ],
   "source": [
    "image = mpimg.imread('../test_images/straight_lines1.jpg')\n",
    "hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "ysize = img.shape[0]\n",
    "\n",
    "gradx_binary = abs_sobel_thresh(hls[:,:,1], orient = 'x', grad_thresh = (20,200))\n",
    "color_binary = color_thresh(hls, color_thresh = (170,255))\n",
    "\n",
    "combined = np.zeros_like(gradx_binary)\n",
    "combined[(gradx_binary == 1) | (color_binary == 1)] = 1\n",
    "\n",
    "top_left = [451,310]\n",
    "bottom_left = [137,ysize]\n",
    "top_right = [505,310]\n",
    "bottom_right = [841,ysize]\n",
    "\n",
    "vertices = np.array([[top_left,top_right,bottom_right,bottom_left]])\n",
    "mask_img = region_of_interest(combined, vertices) \n",
    "plt.imshow(mask_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
